name: fax # only used for demonstration data api
# root_dir: '/data/HangQiu/data/OPV2V/train'
# validate_dir: '/data/HangQiu/data/OPV2V/validate'

# root_dir: '/data/HangQiu/proj/autonet-RL/sub_OPV2V/train'
# validate_dir: '/data/HangQiu/proj/autonet-RL/sub_OPV2V/validate'

root_dir: '/home/shilpa/autoRL/datasets/sub_OPV2V/train'
validate_dir: '/home/shilpa/autoRL/datasets/sub_OPV2V/validate_sub'


train_params:
  batch_size: &batch_size 1
  epoches: &epoches 101
  eval_freq: 1
  save_freq: 1
  max_cav: &max_cav 5
  visible: true


fusion:
  core_method: 'CamIntermediateFusionDataset' # LateFusionDataset, EarlyFusionDataset, IntermediateFusionDataset supported
  args: []


data_augment: []
add_data_extension: ['bev_dynamic.png', 'bev_static.png', 'bev_lane.png', 'bev_visibility.png', 'bev_visibility_corp.png']

# preprocess-related
preprocess:
  # options: BasePreprocessor, VoxelPreprocessor, BevPreprocessor
  core_method: 'RgbPreprocessor'
  args:
    bgr2rgb: true
    resize_x: &image_width 512
    resize_y: &image_height 512
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  # object evaluation range
  cav_lidar_range: &cav_lidar [-50, -50, -3, 50, 50, 1]

#shilpa camera
# # anchor box related
# postprocess:
#   core_method: 'CameraBevPostprocessor' # VoxelPostprocessor, BevPostprocessor supported
#   anchor_args:
#     cav_lidar_range: *cav_lidar
#   order: 'hwl' # hwl or lwh
#   max_num: 100 # maximum number of objects in a single frame. use this number to make sure different frames has the same dimension in the same batch
#   nms_thresh: 0.15

#shilpa lidar
# anchor box related
postprocess:
  core_method: 'CameraBevPostprocessor'
  anchor_args:
    cav_lidar_range: *cav_lidar
    D: 1
    H: 256
    W: 256
    feature_stride: 2
    h: 1.56
    l: 3.9
    num: 2
    r:
      - 0
      - 90
    vd: 4
    vh: 0.4
    vw: 0.4
    w: 1.6
  order: 'hwl'
  target_args:
    neg_threshold: 0.45
    pos_threshold: 0.6
    score_threshold: 0.25
  max_num: 100
  nms_thresh: 0.15
  with_velocity: false

model:
  core_method: corpbevt_lidar
  args:

    #shilpa lidar
    fax_fusion:
      input_dim: 256
      mlp_dim: 256
      agent_size: *max_cav
      window_size: 8
      dim_head: 32
      drop_out: 0.1
      depth: 3
      mask: true
      
    target: &target 'dynamic' # dynamic, static or both
    max_cav: *max_cav

    #shilpa camera
    # encoder:
    #   num_layers: 34
    #   pretrained: true
    #   image_width: *image_width
    #   image_height: *image_height
    #   id_pick: [1, 2, 3]
    #   resize: 0

    #shilpa lidar
    encoder:
      name: 'swint'
      num_layers: 34
      pretrained: true
      image_width: *image_width
      image_height: *image_height
      id_pick: [1, 2, 3]
      resize: 0

    compression: 0 # compression rate

    #shilpa lidar
    camera_neck:
      in_channels: [192, 384, 768]
      out_channels: 256
      num_outs: 3
      no_norm_on_lateral: true
      start_level: 0
      end_level: -1
      upsample_cfg:
        mode: 'bilinear'
        align_corners: false
      norm_cfg:
        type: 'BN2d'
        requires_grad: true
      conv_cfg: 

      act_cfg:
        type: 'ReLU'
        inplace: true

    lidar_encoder:  '/home/shilpa/autoRL/CoBEVT_AutoNet/mmdetection3d/projects/BEVFusion/configs/bevfusion_encoder.py'

    lidar_encoder2:
      type: BEVFusion_Encoder
      data_preprocessor:
        type: Det3DDataPreprocessor
        pad_size_divisor: 32
        voxelize_cfg:
          max_num_points: 10
          point_cloud_range: *cav_lidar
          voxel_size: [0.1, 0.1, 0.2]
          max_voxels: [90000, 120000]
          voxelize_reduce: true
      pts_middle_encoder:
        type: BEVFusionSparseEncoder
        in_channels: 4
        output_channels: 128
        sparse_shape: [512, 512, 41]
        order: [conv, norm, act]
        norm_cfg:
          type: BN1d
          eps: 0.001
          momentum: 0.01
        encoder_channels:
          - [16, 16, 32]
          - [32, 32, 64]
          - [64, 64, 128]
          - [128, 128]
        encoder_paddings:
          - [0, 0, 1]
          - [0, 0, 1]
          - [0, 0, [1, 1, 0]]
          - [0, 0]
        block_type: basicblock
      pts_backbone:
        type: SECOND
        in_channels: 256
        out_channels: [128, 256, 512]
        layer_nums: [5, 5, 5]
        layer_strides: [2, 2, 2]
        norm_cfg:
          type: BN
          eps: 0.001
          momentum: 0.01
        conv_cfg:
          type: Conv2d
          bias: false
      pts_neck:
        type: SECONDFPN
        in_channels: [128, 256, 512]
        out_channels: [128, 128, 128]
        upsample_strides: [1, 2, 4]
        norm_cfg:
          type: BN
          eps: 0.001
          momentum: 0.01
        upsample_cfg:
          type: deconv
          bias: false
        use_conv_for_no_stride: false

    #shilpa camera
    # decoder:
    #   input_dim: 128
    #   num_layer: 3
    #   num_ch_dec: &decoder_block [32, 64, 128]

   #shilpa camera
    # fax:
    #   dim: [128, 128, 128] # b, d, h w from resenet -> b 256 h w
    #   middle: [2, 2, 2] # middle conv
    #   bev_embedding:
    #     sigma: 1.0
    #     bev_height: 256
    #     bev_width: 256
    #     h_meters: &h_meters 100
    #     w_meters: &w_meters 100
    #     offset: 0.0
    #     upsample_scales: [2, 4, 8]

    #   cross_view: #cross_view attention
    #     image_height: *image_height
    #     image_width: *image_width
    #     no_image_features: False
    #     skip: True
    #     heads: [4, 4, 4]
    #     dim_head: [32, 32, 32]
    #     qkv_bias: True

    #   cross_view_swap:
    #     rel_pos_emb: False
    #     q_win_size: [ [ 16, 16 ], [ 16, 16 ], [ 32, 32 ] ]
    #     feat_win_size: [ [ 8, 8 ], [ 8, 8 ], [ 16, 16 ] ]
    #     bev_embedding_flag: [ true, false, false ]



      # self_attn:
      #   dim_head: 32
      #   dropout: 0.1
      #   window_size: 32


    #shilpa lidar
    fax:
      dim: [256, 256, 256]
      middle: [2, 2, 2]
      bev_embedding:
        sigma: 1.0
        bev_height: 256
        bev_width: 256
        h_meters: &h_meters 100
        w_meters: &w_meters 100
        offset: 0.0
        upsample_scales: [2, 4, 8]
      cross_view:
        image_height: *image_height
        image_width: *image_width
        no_image_features: false
        skip: true
        heads: [4, 4, 4]
        dim_head: [32, 32, 32]
        qkv_bias: true
      cross_view_swap:
        rel_pos_emb: false
        q_win_size: [[16, 16], [16, 16], [32, 32]]
        feat_win_size: [[8, 8], [8, 8], [16, 16]]
        bev_embedding_flag: [true, false, false]
      self_attn:
        dim_head: 32
        dropout: 0.2
        window_size: 64

    #shilpa camera
    # sttf: &sttf
    #   resolution: 0.390625 # m/pixel
    #   downsample_rate: 8
    #   use_roi_mask: true

    #shilpa lidar
    sttf: &sttf
      resolution: 0.390625
      downsample_rate: 4
      use_roi_mask: true

    #shilpa camera
    # fax_fusion:
    #   input_dim: 128
    #   mlp_dim: 256
    #   agent_size: *max_cav
    #   window_size: 8
    #   dim_head: 32
    #   drop_out: 0.1
    #   depth: 3
    #   mask: true

    #shilpa lidar
    fax_image_fusion:
      input_dim: 256
      mlp_dim: 256
      agent_size: *max_cav
      window_size: 8
      dim_head: 32
      drop_out: 0.1
      depth: 3
      mask: true

    fax_lidar_fusion:
      input_dim: 512
      mlp_dim: 768
      agent_size: *max_cav
      window_size: 8
      dim_head: 32
      drop_out: 0.1
      depth: 3
      mask: true   

    decoder:
      input_dim: 256
      num_layer: 3
      num_ch_dec: &decoder_block [32, 64, 128]
      only_camera:
        input_dim: 256
        num_layer: 3
        num_ch_dec: [32, 128, 512]
      only_lidar:
        input_dim: 384
        num_layer: 3
        num_ch_dec: [32, 128, 512]
      modality_after_agent:
        input_dim: 512
        num_layer: 3
        num_ch_dec: [32, 128, 512]
      modality_before_agent:
        input_dim: 512
        num_layer: 3
        num_ch_dec: [32, 128, 512]

    fuse:
      fuse_type: 'modality_after_agent'
      fuse_method: 'conv'
      fuse_out_channels: 512 
 

    seg_head_dim: 32
    output_class: 2

    pts_bbox_head:
      type: bevfusion_det_head # DETR3DHead
      num_query: 900
      num_classes: 2
      in_channels: &in_channels 512
      sync_cls_avg_factor: true
      with_box_refine: true
      as_two_stage: false
      transformer:
        type: Detr3DTransformer
        num_cams: 4
        decoder:
          type: Detr3DTransformerDecoder
          num_layers: 6
          return_intermediate: true
          transformerlayers:
            type: mmdet.DetrTransformerDecoderLayer
            attn_cfgs:
              - type: MultiheadAttention
                embed_dims: *in_channels
                num_heads: 8
                dropout: 0.2
              - type: Detr3DCrossAtten
                pc_range: *cav_lidar
                num_points: 1
                embed_dims: *in_channels
            feedforward_channels: 512
            ffn_dropout: 0.2
            operation_order:
              - self_attn
              - norm
              - cross_attn
              - norm
              - ffn
              - norm
      code_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
      bbox_coder:
        type: NMSFreeCoder
        post_center_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        pc_range: *cav_lidar
        max_num: 100
        voxel_size: [0.2, 0.2, 8]
        num_classes: 2
      positional_encoding:
        type: mmdet.SinePositionalEncoding
        num_feats: 256 
        normalize: true
        offset: -0.5
      loss_cls:
        type: FocalLoss
        use_sigmoid: true
        gamma: 2.0
        alpha: 0.25
        loss_weight: 1.0
      loss_bbox:
        type: L1Loss
        loss_weight: 1.0
      loss_iou:
        type: IoULoss
        loss_weight: 1.0
        reduction: mean

loss:
  core_method: detr_loss
  args:
    iou_loss_weight: 0.0
    bbox_loss_weight: 1.0
    cls_loss_weight: 1.0
    heatmap_loss_weight: 1.0

optimizer:
  core_method: AdamW
  lr: 2e-5
  args:
    eps: 1e-10
    weight_decay: 5e-3

lr_scheduler:
  core_method: cosineannealwarm
  epoches: *epoches
  warmup_lr: 1e-5
  warmup_epoches: 3
  lr_min: 5e-6
  k_decay: 1


    
#shilpa camera   
# loss:
#   core_method: vanilla_seg_loss
#   args:
#     target: *target
#     d_weights: 75.0
#     s_weights: 15.0
#     d_coe: 2.0
#     s_coe: 0.0

#shilpa camera
# optimizer:
#   core_method: AdamW
#   lr: 2e-4
#   args:
#     eps: 1e-10
#     weight_decay: 1e-2

# lr_scheduler:
#     core_method: cosineannealwarm #step, multistep, Exponential and cosineannealwarm support
#     epoches: *epoches
#     warmup_lr: 2e-5
#     warmup_epoches: 10
#     lr_min: 5e-6

